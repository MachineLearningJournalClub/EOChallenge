{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fead60a1-7224-4553-b403-18cb9bc624c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "from xcube_sh.config import CubeConfig\n",
    "from xcube_sh.cube import open_cube\n",
    "from shapely import geometry\n",
    "from xcube_sh.sentinelhub import SentinelHub\n",
    "import xarray as xr\n",
    "import json\n",
    "import IPython.display\n",
    "import shapely.geometry\n",
    "\n",
    "from sentinelhub import BBox, WmsRequest, DataSource, SHConfig\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e2e0e8-8b6b-4812-9728-81cce97c09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Sentinel Hub credentials\n",
    "\n",
    "import os\n",
    "sh_credentials = dict(client_id=os.environ['SH_CLIENT_ID'],\n",
    "                      client_secret=os.environ['SH_CLIENT_SECRET']) # This is only provided when the Oauth credentials are created\n",
    "\n",
    "# Sentinel-3 OLCI, Sentinel-3 SLSTR and Sentinel-5 layers are processed on different infrastructure, \n",
    "# which requires to used different end-point\n",
    "\n",
    "sh_credentials.update(api_url='https://creodias.sentinel-hub.com') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc74128e-642a-4f2d-a2a1-785fb626a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('countries.json')\n",
    "data=json.load(f)\n",
    "final=dict()\n",
    "for i in range(0,len(data['features'])):\n",
    "    #print(data['features'][i]['id'])\n",
    "    final[data['features'][i]['id']]=data['features'][i]['geometry']['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf1402e-b3f7-4b7d-bdca-6538cfc6757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EU_countries={'AUT','BEL','BGR','HRV','CYP','CZE','DNK','EST','FIN','FRA','DEU','GRC',\n",
    "'HUN','ITA','LVA','LTU','LUX','MLT','NLD','POL','PRT','ROU','SVK','SVN','ESP',\n",
    "'SWE','ALB','ARM','BLR','BIH','GEO','ISL',\n",
    "'MKD','MDA','MCO','MNE','NOR','RUS','SRB','CHE','TUR','UKR','GBR'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "658b203a-50cf-4122-bec7-e5d057524356",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = pd.DataFrame()\n",
    "for country in EU_countries:\n",
    "    if len(final[country])!=1:\n",
    "        xs=0\n",
    "        ys=0\n",
    "        all_x=[]\n",
    "        all_y=[]\n",
    "        for i in range(0,len(final[country])):\n",
    "            state=geometry.Polygon(final[country][i][0])\n",
    "            geom = np.array(state.exterior.coords.xy)\n",
    "            xs = geom[0]\n",
    "            ys = geom[1]\n",
    "            all_x.extend(xs)\n",
    "            all_y.extend(ys)\n",
    "    else:\n",
    "        state=geometry.Polygon(final[country][0])\n",
    "        geom = np.array(state.exterior.coords.xy)\n",
    "        all_x = geom[0]\n",
    "        all_y = geom[1]\n",
    "    aoi=aoi.append([ [country,\n",
    "                    min(all_x),\n",
    "                    min(all_y),\n",
    "                    max(all_x),\n",
    "                    max(all_y)]],ignore_index='True')\n",
    "bbox=(min(all_x),\n",
    "min(all_y),\n",
    "max(all_x),\n",
    "max(all_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7595247e-f8c7-445b-bc07-3a227e22d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox=(min(all_x),\n",
    "min(all_y),\n",
    "max(all_x),\n",
    "max(all_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abdc5404-a77d-4e6f-93e6-be2553d78e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/geo+json": {
       "coordinates": [
        [
         [
          34.004881,
          34.571869
         ],
         [
          34.004881,
          35.173125
         ],
         [
          32.256667,
          35.173125
         ],
         [
          32.256667,
          34.571869
         ],
         [
          34.004881,
          34.571869
         ]
        ]
       ],
       "type": "Polygon"
      },
      "text/plain": [
       "<IPython.display.GeoJSON object>"
      ]
     },
     "metadata": {
      "application/geo+json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c44bcfc4-dde2-4375-bbd5-d606677ad5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 5)\n",
      "     0          1          2          3          4\n",
      "0  FRA  -4.592350  41.380007   9.560016  51.148506\n",
      "1  LVA  21.055800  55.615107  28.176709  57.970157\n",
      "2  LTU  21.055800  53.905702  26.588279  56.372528\n",
      "3  CHE   6.022609  45.776948  10.442701  47.830828\n",
      "4  BLR  23.199494  51.319503  32.693643  56.169130\n",
      "5  MLT  14.180354  35.820191  14.566171  36.075809\n",
      "6  ISL -24.326184  63.496383 -13.609732  66.526792\n",
      "7  ARM  43.582746  38.741201  46.505720  41.248129\n",
      "Shape of 2020 DF: (43, 5), Count of Null values: 0\n"
     ]
    }
   ],
   "source": [
    "print(aoi.shape)\n",
    "print(aoi.head(8))\n",
    "\n",
    "shape = aoi.shape\n",
    "nullCount = sum(aoi.isna().sum())\n",
    "print(f\"Shape of 2020 DF: {shape}, Count of Null values: {nullCount}\".format(shape , nullCount ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47947519-2586-41e6-9df8-b50ee28716c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculateNO2(geometry, timerange):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    geometry: BBox object to be passed. This contains the bounding box for the area of interest (AOI)\n",
    "    timerange: list giving the start & end of the time range format: YYYY-mm-dd\n",
    "    \n",
    "    return:\n",
    "    a dataframe with two columns: Mean NO2 and Timestamp\n",
    "    NO2 mean values for the time span between given timerange \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cube_config = CubeConfig(dataset_name='S5PL2',\n",
    "                         band_names=['NO2'],\n",
    "                         tile_size=[512, 512],\n",
    "                         geometry=geometry,\n",
    "                         spatial_res=(bbox[2]-bbox[0])/512, # spatial resolution (approx. 20 m in degree)\n",
    "                         time_range= timerange,\n",
    "                         time_period='7D') \n",
    "    cube = open_cube(cube_config, **sh_credentials)\n",
    "\n",
    "    no2_values = list() \n",
    "    timestamp = list()\n",
    "\n",
    "    for i in range(cube.time.shape[0]):\n",
    "        no2_values.append(np.nanmean(cube.NO2.isel(time=i).values[0]))\n",
    "        timestamp.append(cube.NO2.isel(time=i).time.values)\n",
    "        \n",
    "    assert len(no2_values) == len(timestamp)\n",
    "    \n",
    "    return pd.DataFrame({'DateTime': timestamp, 'Mean NO2': no2_values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f9fbf812-ccee-463c-9121-d91d086ee0c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f6024c-0861-4026-9e54-d8b5e629e0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "start = time.time()\n",
    "aoi_no2 = list()\n",
    "\n",
    "# Check length of provided aoi list OR dataframe\n",
    "len_aoi = len(aoi)\n",
    "\n",
    "# Define how many AOIs you want to process. For the demo we will use only one \n",
    "counter = 42\n",
    "\n",
    "for idx in range(counter):\n",
    "    aoi_dict = dict()\n",
    "    \n",
    "    aoi_dict['Country_BBox'] = aoi[0][idx]\n",
    "    print(\"Processing: \", aoi_dict['Country_BBox'])\n",
    "    x1 = int(aoi[1][idx])  # degree \n",
    "    y1 = int(aoi[2][idx])  # degree\n",
    "    x2 = int(aoi[3][idx])  # degree\n",
    "    y2 = int(aoi[4][idx])  # degree\n",
    "\n",
    "    bbox = x1, y1, x2, y2\n",
    "    \n",
    "    timerange = ['2020-01-01', '2020-12-01']\n",
    "    aoi_dict['NO2_2020'] = caculateNO2(bbox, timerange)\n",
    "    shape = aoi_dict['NO2_2020'].shape\n",
    "    nullCount = sum(aoi_dict['NO2_2020'].isna().sum())\n",
    "    print(f\"Shape of 2020 DF: {shape}, Count of Null values: {nullCount}\".format(shape , nullCount ))\n",
    "    \n",
    "    timerange = ['2019-01-01', '2019-12-01']\n",
    "    aoi_dict['NO2_2019'] = caculateNO2(bbox, timerange)\n",
    "    shape = aoi_dict['NO2_2019'].shape\n",
    "    nullCount = sum(aoi_dict['NO2_2019'].isna().sum())\n",
    "    print(f\"Shape of 2019 DF: {shape}, Count of Null values: {nullCount}\".format(shape , nullCount ))    \n",
    "    \n",
    "    timerange = ['2018-03-01', '2018-12-01']\n",
    "    aoi_dict['NO2_2018'] = caculateNO2(bbox, timerange)\n",
    "    shape = aoi_dict['NO2_2018'].shape\n",
    "    nullCount = sum(aoi_dict['NO2_2018'].isna().sum())\n",
    "    print(f\"Shape of 2018 DF: {shape}, Count of Null values: {nullCount}\".format(shape , nullCount ))\n",
    "\n",
    "    aoi_no2.append(aoi_dict)\n",
    "\n",
    "end = time.time()\n",
    "IPython.display.GeoJSON(shapely.geometry.box(*bbox).__geo_interface__)\n",
    "#print(len(aoi_no2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6db35579-0fdd-4b91-b099-58e686cf8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "print(len(aoi_no2))\n",
    "with open('aoi_list_no2.pkl', 'wb') as f:\n",
    "    pickle.dump(aoi_no2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d34144a2-66f0-405d-a895-ee61fdce6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('aoi_list_no2.pkl', 'rb') as fp:\n",
    "    loaded = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2f762390-c7d5-4592-88ca-3f8f96266033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Country_BBox': 'TUR',\n",
       "  'NO2_2020':               DateTime  Mean NO2\n",
       "  0  2020-01-04 12:00:00  0.000015\n",
       "  1  2020-01-11 12:00:00  0.000023\n",
       "  2  2020-01-18 12:00:00  0.000032\n",
       "  3  2020-01-25 12:00:00  0.000025\n",
       "  4  2020-02-01 12:00:00  0.000028\n",
       "  5  2020-02-08 12:00:00  0.000032\n",
       "  6  2020-02-15 12:00:00  0.000019\n",
       "  7  2020-02-22 12:00:00  0.000027\n",
       "  8  2020-02-29 12:00:00  0.000020\n",
       "  9  2020-03-07 12:00:00  0.000022\n",
       "  10 2020-03-14 12:00:00  0.000013\n",
       "  11 2020-03-21 12:00:00  0.000018\n",
       "  12 2020-03-28 12:00:00  0.000012\n",
       "  13 2020-04-04 12:00:00  0.000013\n",
       "  14 2020-04-11 12:00:00  0.000028\n",
       "  15 2020-04-18 12:00:00       NaN\n",
       "  16 2020-04-25 12:00:00  0.000013\n",
       "  17 2020-05-02 12:00:00  0.000019\n",
       "  18 2020-05-09 12:00:00  0.000019\n",
       "  19 2020-05-16 12:00:00  0.000015\n",
       "  20 2020-05-23 12:00:00  0.000009\n",
       "  21 2020-05-30 12:00:00  0.000009\n",
       "  22 2020-06-06 12:00:00  0.000016\n",
       "  23 2020-06-13 12:00:00  0.000013\n",
       "  24 2020-06-20 12:00:00  0.000021\n",
       "  25 2020-06-27 12:00:00  0.000017\n",
       "  26 2020-07-04 12:00:00  0.000017\n",
       "  27 2020-07-11 12:00:00  0.000017\n",
       "  28 2020-07-18 12:00:00  0.000017\n",
       "  29 2020-07-25 12:00:00  0.000022\n",
       "  30 2020-08-01 12:00:00  0.000020\n",
       "  31 2020-08-08 12:00:00  0.000020\n",
       "  32 2020-08-15 12:00:00  0.000018\n",
       "  33 2020-08-22 12:00:00  0.000017\n",
       "  34 2020-08-29 12:00:00  0.000016\n",
       "  35 2020-09-05 12:00:00  0.000018\n",
       "  36 2020-09-12 12:00:00  0.000018\n",
       "  37 2020-09-19 12:00:00  0.000012\n",
       "  38 2020-09-26 12:00:00  0.000019\n",
       "  39 2020-10-03 12:00:00  0.000018\n",
       "  40 2020-10-10 12:00:00  0.000027\n",
       "  41 2020-10-17 12:00:00  0.000015\n",
       "  42 2020-10-24 12:00:00  0.000025\n",
       "  43 2020-10-31 12:00:00  0.000021\n",
       "  44 2020-11-07 12:00:00  0.000017\n",
       "  45 2020-11-14 12:00:00  0.000026\n",
       "  46 2020-11-21 12:00:00  0.000026\n",
       "  47 2020-11-28 12:00:00  0.000017,\n",
       "  'NO2_2019':               DateTime  Mean NO2\n",
       "  0  2019-01-04 12:00:00  0.000014\n",
       "  1  2019-01-11 12:00:00  0.000021\n",
       "  2  2019-01-18 12:00:00  0.000020\n",
       "  3  2019-01-25 12:00:00  0.000034\n",
       "  4  2019-02-01 12:00:00  0.000024\n",
       "  5  2019-02-08 12:00:00  0.000027\n",
       "  6  2019-02-15 12:00:00  0.000029\n",
       "  7  2019-02-22 12:00:00  0.000019\n",
       "  8  2019-03-01 12:00:00  0.000017\n",
       "  9  2019-03-08 12:00:00  0.000025\n",
       "  10 2019-03-15 12:00:00  0.000022\n",
       "  11 2019-03-22 12:00:00  0.000016\n",
       "  12 2019-03-29 12:00:00  0.000014\n",
       "  13 2019-04-05 12:00:00  0.000016\n",
       "  14 2019-04-12 12:00:00  0.000017\n",
       "  15 2019-04-19 12:00:00  0.000022\n",
       "  16 2019-04-26 12:00:00  0.000018\n",
       "  17 2019-05-03 12:00:00  0.000017\n",
       "  18 2019-05-10 12:00:00  0.000014\n",
       "  19 2019-05-17 12:00:00  0.000014\n",
       "  20 2019-05-24 12:00:00  0.000018\n",
       "  21 2019-05-31 12:00:00  0.000018\n",
       "  22 2019-06-07 12:00:00  0.000020\n",
       "  23 2019-06-14 12:00:00  0.000021\n",
       "  24 2019-06-21 12:00:00  0.000016\n",
       "  25 2019-06-28 12:00:00  0.000016\n",
       "  26 2019-07-05 12:00:00  0.000018\n",
       "  27 2019-07-12 12:00:00       NaN\n",
       "  28 2019-07-19 12:00:00  0.000020\n",
       "  29 2019-07-26 12:00:00  0.000016\n",
       "  30 2019-08-02 12:00:00  0.000014\n",
       "  31 2019-08-09 12:00:00  0.000019\n",
       "  32 2019-08-16 12:00:00  0.000019\n",
       "  33 2019-08-23 12:00:00  0.000017\n",
       "  34 2019-08-30 12:00:00  0.000022\n",
       "  35 2019-09-06 12:00:00  0.000021\n",
       "  36 2019-09-13 12:00:00  0.000017\n",
       "  37 2019-09-20 12:00:00  0.000012\n",
       "  38 2019-09-27 12:00:00  0.000019\n",
       "  39 2019-10-04 12:00:00  0.000012\n",
       "  40 2019-10-11 12:00:00  0.000018\n",
       "  41 2019-10-18 12:00:00  0.000019\n",
       "  42 2019-10-25 12:00:00  0.000016\n",
       "  43 2019-11-01 12:00:00  0.000029\n",
       "  44 2019-11-08 12:00:00  0.000037\n",
       "  45 2019-11-15 12:00:00  0.000025\n",
       "  46 2019-11-22 12:00:00  0.000018\n",
       "  47 2019-11-29 12:00:00  0.000031,\n",
       "  'NO2_2018':               DateTime  Mean NO2\n",
       "  0  2018-03-04 12:00:00       NaN\n",
       "  1  2018-03-11 12:00:00       NaN\n",
       "  2  2018-03-18 12:00:00       NaN\n",
       "  3  2018-03-25 12:00:00       NaN\n",
       "  4  2018-04-01 12:00:00       NaN\n",
       "  5  2018-04-08 12:00:00       NaN\n",
       "  6  2018-04-15 12:00:00       NaN\n",
       "  7  2018-04-22 12:00:00       NaN\n",
       "  8  2018-04-29 12:00:00  0.000023\n",
       "  9  2018-05-06 12:00:00  0.000015\n",
       "  10 2018-05-13 12:00:00  0.000013\n",
       "  11 2018-05-20 12:00:00  0.000018\n",
       "  12 2018-05-27 12:00:00  0.000025\n",
       "  13 2018-06-03 12:00:00  0.000022\n",
       "  14 2018-06-10 12:00:00  0.000018\n",
       "  15 2018-06-17 12:00:00  0.000017\n",
       "  16 2018-06-24 12:00:00  0.000020\n",
       "  17 2018-07-01 12:00:00  0.000022\n",
       "  18 2018-07-08 12:00:00  0.000029\n",
       "  19 2018-07-15 12:00:00  0.000023\n",
       "  20 2018-07-22 12:00:00  0.000026\n",
       "  21 2018-07-29 12:00:00       NaN\n",
       "  22 2018-08-05 12:00:00  0.000020\n",
       "  23 2018-08-12 12:00:00  0.000018\n",
       "  24 2018-08-19 12:00:00  0.000020\n",
       "  25 2018-08-26 12:00:00  0.000021\n",
       "  26 2018-09-02 12:00:00  0.000017\n",
       "  27 2018-09-09 12:00:00  0.000019\n",
       "  28 2018-09-16 12:00:00  0.000010\n",
       "  29 2018-09-23 12:00:00  0.000016\n",
       "  30 2018-09-30 12:00:00  0.000020\n",
       "  31 2018-10-07 12:00:00  0.000020\n",
       "  32 2018-10-14 12:00:00  0.000021\n",
       "  33 2018-10-21 12:00:00  0.000026\n",
       "  34 2018-10-28 12:00:00  0.000019\n",
       "  35 2018-11-04 12:00:00  0.000018\n",
       "  36 2018-11-11 12:00:00  0.000018\n",
       "  37 2018-11-18 12:00:00       NaN\n",
       "  38 2018-11-25 12:00:00  0.000015\n",
       "  39 2018-12-02 12:00:00  0.000029}]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f396beb2-52bf-4189-b8ca-37a519f989c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDC 0.24.5 (Python3)",
   "language": "python",
   "name": "edc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
