{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from Sentinel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this notebook is possible to retrieve the data of the Sentinel Client Server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from xcube_sh.config import CubeConfig\n",
    "from xcube_sh.cube import open_cube\n",
    "from shapely import geometry\n",
    "from xcube_sh.sentinelhub import SentinelHub\n",
    "import json\n",
    "import IPython.display\n",
    "import shapely.geometry\n",
    "import numpy as np\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Sentinel Hub credentials\n",
    "sh_credentials = dict(client_id='3fb32c3f-01e8-4f6c-8dd9-09e2a4f355aa',\n",
    "                      client_secret=\"*;V|cHMKY50lFH+PZFR;yUP41Q%}aBiV_:R0]09v\")\n",
    "\n",
    "# Sentinel-3 OLCI, Sentinel-3 SLSTR and Sentinel-5 layers are processed on different infrastructure, \n",
    "# which requires to used different end-point\n",
    "\n",
    "sh_credentials.update(api_url='https://creodias.sentinel-hub.com')\n",
    "\n",
    "countries=['PER']\n",
    "timerange = ['2018-04-01', '2020-12-31']\n",
    "dataset=\"S5PL2\"\n",
    "variables=['O3','NO2','SO2','CO','CH4']\n",
    "period=\"7D\"\n",
    "resolution=512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import 'countries.json', a file with a dictionary full of coordinates for the different states. From here we can extract some coordinates to build a box around each country and download the required dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('countries.json')\n",
    "shape_country=json.load(f)\n",
    "shape_bbox=dict()\n",
    "for i in range(0,len(shape_country['features'])):\n",
    "    shape_bbox[shape_country['features'][i]['id']]=shape_country['features'][i]['geometry']['coordinates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data download requires a lot of time we created a list were you can indicate some of the countries you want to download. We advise to download 5 or 6 countries at the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = dict()\n",
    "for country in countries:\n",
    "    if len(shape_bbox[country])!=1:\n",
    "        xs=0\n",
    "        ys=0\n",
    "        all_x=[]\n",
    "        all_y=[]\n",
    "        for i in range(0,len(shape_bbox[country])):\n",
    "            state=geometry.Polygon(shape_bbox[country][i][0])\n",
    "            geom = np.array(state.exterior.coords.xy)\n",
    "            xs = geom[0]\n",
    "            ys = geom[1]\n",
    "            all_x.extend(xs)\n",
    "            all_y.extend(ys)\n",
    "    else:\n",
    "        state=geometry.Polygon(shape_bbox[country][0])\n",
    "        geom = np.array(state.exterior.coords.xy)\n",
    "        all_x = geom[0]\n",
    "        all_y = geom[1]\n",
    "    aoi[country]=(min(all_x),\n",
    "                    min(all_y),\n",
    "                    max(all_x),\n",
    "                    max(all_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a function is responsible to indicate the data we want to have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate(geometry, timerange):\n",
    "    \n",
    "    cube_config = CubeConfig(dataset_name=dataset,\n",
    "                         band_names=variables,\n",
    "                         tile_size=[resolution, resolution],\n",
    "                         bbox=geometry,\n",
    "                         spatial_res=abs(geometry[2]-geometry[0])/resolution,\n",
    "                         time_range= timerange,\n",
    "                         time_period=period) \n",
    "    cube = open_cube(cube_config, **sh_credentials)\n",
    "    return cube.mean(dim=[\"lon\",\"lat\"],skipna=True).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  PER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andry/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/home/andry/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/home/andry/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/home/andry/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n",
      "/home/andry/anaconda3/lib/python3.7/site-packages/dask/array/numpy_compat.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 2018 DF: (288, 6), Count of Null values: 128\n"
     ]
    }
   ],
   "source": [
    "aoi_S5PL2 = list()\n",
    "\n",
    "for i in aoi.keys():\n",
    "    aoi_dict = dict()\n",
    "    print(\"Processing: \", i)\n",
    "    aoi_dict[str(i)] = caculate(aoi[str(i)], timerange)\n",
    "    shape = aoi_dict[str(i)].shape\n",
    "    nullCount = sum(aoi_dict[str(i)].isna().sum())\n",
    "    print(f\"Shape of 2018 DF: {shape}, Count of Null values: {nullCount}\".format(shape , nullCount ))\n",
    "\n",
    "    aoi_S5PL2.append(aoi_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final file can be then exported. We downloaded it as a pickle, but other formats would be feasible as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(countries)>1:\n",
    "    name_file=\"_\".join(countries)\n",
    "else:\n",
    "    name_file=str(countries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data/data_countries/'+name_file+'.pkl', 'wb') as f:\n",
    "    pickle.dump(aoi_S5PL2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
