{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from Sentinel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this notebook is possible to retrieve the data of the Sentinel Client Server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "from xcube_sh.config import CubeConfig\n",
    "from xcube_sh.cube import open_cube\n",
    "from shapely import geometry\n",
    "from xcube_sh.sentinelhub import SentinelHub\n",
    "import xarray as xr\n",
    "import json\n",
    "import IPython.display\n",
    "import shapely.geometry\n",
    "\n",
    "from sentinelhub import BBox, WmsRequest, DataSource, SHConfig\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Sentinel Hub credentials\n",
    "import os\n",
    "sh_credentials = dict(client_id=os.environ['SH_CLIENT_ID'],\n",
    "                      client_secret=os.environ['SH_CLIENT_SECRET']) # This is only provided when the Oauth credentials are created\n",
    "\n",
    "# Sentinel-3 OLCI, Sentinel-3 SLSTR and Sentinel-5 layers are processed on different infrastructure, \n",
    "# which requires to used different end-point\n",
    "\n",
    "sh_credentials.update(api_url='https://creodias.sentinel-hub.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import 'countries.json', a file with a dictionary full of coordinates for the different states. From here we can extract some coordinates to build a box around each country and download the required dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('countries.json')\n",
    "data=json.load(f)\n",
    "final=dict()\n",
    "for i in range(0,len(data['features'])):\n",
    "    final[data['features'][i]['id']]=data['features'][i]['geometry']['coordinates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data download requires a lot of time we created a list were you can indicate some of the countries you want to download. We advise to download 5 or 6 countries at the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EU_countries={'PER','VEN','CHL','ECU','GTM','BOL'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = dict()\n",
    "for country in EU_countries:\n",
    "    if len(final[country])!=1:\n",
    "        xs=0\n",
    "        ys=0\n",
    "        all_x=[]\n",
    "        all_y=[]\n",
    "        for i in range(0,len(final[country])):\n",
    "            state=geometry.Polygon(final[country][i][0])\n",
    "            geom = np.array(state.exterior.coords.xy)\n",
    "            xs = geom[0]\n",
    "            ys = geom[1]\n",
    "            all_x.extend(xs)\n",
    "            all_y.extend(ys)\n",
    "    else:\n",
    "        state=geometry.Polygon(final[country][0])\n",
    "        geom = np.array(state.exterior.coords.xy)\n",
    "        all_x = geom[0]\n",
    "        all_y = geom[1]\n",
    "    aoi[country]=(min(all_x),\n",
    "                    min(all_y),\n",
    "                    max(all_x),\n",
    "                    max(all_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a function is responsible to indicate the data we want to have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate(geometry, timerange):\n",
    "    \n",
    "    cube_config = CubeConfig(dataset_name='S5PL2',\n",
    "                         band_names=['O3','NO2','SO2','CO','CH4'],\n",
    "                         tile_size=[512, 512],\n",
    "                         bbox=geometry,\n",
    "                         spatial_res=abs(geometry[2]-geometry[0])/512, # spatial resolution (approx. 20 m in degree)\n",
    "                         time_range= timerange,\n",
    "                         time_period='7D') \n",
    "    cube = open_cube(cube_config, **sh_credentials)\n",
    "    return cube.mean(dim=[\"lon\",\"lat\"],skipna=True).to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  DEU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/eurodatacube-0.24.5/lib/python3.8/site-packages/dask/array/numpy_compat.py:39: RuntimeWarning: invalid value encountered in true_divide\n",
      "  x = np.divide(x1, x2, out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 2018 DF: (288, 6), Count of Null values: 204\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start = time.time()\n",
    "aoi_S5PL2 = list()\n",
    "\n",
    "# Check length of provided aoi list OR dataframe\n",
    "len_aoi = len(aoi)\n",
    "\n",
    "# Define how many AOIs you want to process. For the demo we will use only one \n",
    "counter = 6\n",
    "\n",
    "for i in aoi.keys():\n",
    "    aoi_dict = dict()\n",
    "    print(\"Processing: \", i)      \n",
    "    timerange = ['2018-04-01', '2020-12-31']\n",
    "    aoi_dict[str(i)] = caculate(aoi[str(i)], timerange)\n",
    "    shape = aoi_dict[str(i)].shape\n",
    "    nullCount = sum(aoi_dict[str(i)].isna().sum())\n",
    "    print(f\"Shape of 2018 DF: {shape}, Count of Null values: {nullCount}\".format(shape , nullCount ))\n",
    "\n",
    "    aoi_S5PL2.append(aoi_dict)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final file can be then exported. We downloaded it as a pickle, but other formats would be feasible as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
